---
layout: single
classes: wide
author_profile: true
read_time: true
share: true
related: true
title:  "Getting Started with Local LLMs using Ollama"
date:   2025-04-11 00:19:05 +1000
categories:
  - Artificial Intelligence (AI)
  - Machine Learning (ML)
tags:
  - AI Security
  - LLM
  - Ollama
---

Large Language Models (LLMs) have revolutionised the way we interact with machines. While powerful cloud-hosted LLMs come with trade-offs in terms of cost, limited API calls, credits and privacy. This is where Ollama comes in handy. It is a tool designed to run open-source LLMs locally with ease.

In this blog, we will break down what LLMs are, how tools like Ollama can help run LLMs locally on a machine and how to build a local Retrieval Augmented Generation (RAG) setup with a vector database and your own custom model.

